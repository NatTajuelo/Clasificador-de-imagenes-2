{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cargamos el conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo ZIP\n",
    "zip_path = \"../dogs-vs-cats.zip\" \n",
    "extract_to = \"../data/raw\"       \n",
    "\n",
    "# Extraer el archivo ZIP\n",
    "if os.path.exists(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(f\"Archivo extraído correctamente en: {extract_to}\")\n",
    "else:\n",
    "    print(f\"El archivo ZIP no existe en la ruta: {zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo ZIP\n",
    "zip_path = \"../data/raw/train.zip\" \n",
    "extract_to = \"../data/raw\"       \n",
    "\n",
    "# Extraer el archivo ZIP\n",
    "if os.path.exists(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(f\"Archivo extraído correctamente en: {extract_to}\")\n",
    "else:\n",
    "    print(f\"El archivo ZIP no existe en la ruta: {zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta al archivo ZIP\n",
    "zip_path = \"../data/raw/test1.zip\" \n",
    "extract_to = \"../data/raw\"       \n",
    "\n",
    "# Extraer el archivo ZIP\n",
    "if os.path.exists(zip_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "    print(f\"Archivo extraído correctamente en: {extract_to}\")\n",
    "else:\n",
    "    print(f\"El archivo ZIP no existe en la ruta: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualización y preprocesamiento de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carpetas de entrada y salida\n",
    "input_dir = \"../data/raw/train\"\n",
    "output_dir = \"../data/processed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Procesar imágenes\n",
    "image_size = (255, 255)\n",
    "categories = ['cat', 'dog']\n",
    "\n",
    "# Crear carpetas de salida para cada categoría\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(output_dir, category), exist_ok=True)\n",
    "\n",
    "# Redimensionar y mover las imágenes\n",
    "for filename in os.listdir(input_dir):\n",
    "    category = 'cat' if 'cat' in filename else 'dog'\n",
    "    img_path = os.path.join(input_dir, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        img_resized = cv2.resize(img, image_size)\n",
    "        save_path = os.path.join(output_dir, category, filename)\n",
    "        cv2.imwrite(save_path, img_resized)\n",
    "\n",
    "print(\"Todas las imágenes han sido redimensionadas y clasificadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_images = [os.path.join(output_dir, \"cat\", img) for img in os.listdir(os.path.join(output_dir, \"cat\"))[:9]]\n",
    "dog_images = [os.path.join(output_dir, \"dog\", img) for img in os.listdir(os.path.join(output_dir, \"dog\"))[:9]]\n",
    "\n",
    "def plot_images(image_paths, title):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        img = cv2.imread(img_path)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_images(cat_images, \"Ejemplos de Gatos\")\n",
    "plot_images(dog_images, \"Ejemplos de Perros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construir la Red Neuronal Convolucional (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(200, 200, 3)),\n",
    "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/processed\"\n",
    "datagen = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir, target_size=(200, 200), batch_size=32, class_mode='categorical', subset='training')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    train_dir, target_size=(200, 200), batch_size=32, class_mode='categorical', subset='validation')\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Precisión en el conjunto de validación: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"../models/img-classificator\", monitor = \"val_accuracy\", verbose = 1, save_best_only = True, save_weights_only = False, mode = \"auto\")\n",
    "early = EarlyStopping(monitor = \"val_accuracy\", patience = 3, verbose = 1, mode = \"auto\")\n",
    "hist = model.fit(train_data, steps_per_epoch = 100, validation_data = test_data, validation_steps = 10, epochs = 3, callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Visualización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history[\"val_accuracy\"])\n",
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\", \"Loss\", \"Validation Loss\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"../data/raw/test/9.jpg\", target_size = (200, 200))\n",
    "img = np.asarray(img)\n",
    "plt.imshow(img)\n",
    "img = np.expand_dims(img, axis = 0)\n",
    "saved_model = load_model(\"../models/vgg16_1.h5\")\n",
    "output = saved_model.predict(img)\n",
    "if output[0][0] > output[0][1]:\n",
    "    print(\"cat\")\n",
    "else:\n",
    "    print(\"dog\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
